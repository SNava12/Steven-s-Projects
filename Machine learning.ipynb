{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cc9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8013eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (195, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "..              ...          ...           ...           ...             ...   \n",
       "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
       "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
       "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
       "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
       "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "..                ...       ...       ...         ...           ...  ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
       "\n",
       "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "..           ...      ...     ...     ...       ...       ...       ...   \n",
       "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
       "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
       "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
       "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
       "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
       "\n",
       "      spread2        D2       PPE  \n",
       "0    0.266482  2.301442  0.284654  \n",
       "1    0.335590  2.486855  0.368674  \n",
       "2    0.311173  2.342259  0.332634  \n",
       "3    0.334147  2.405554  0.368975  \n",
       "4    0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...  \n",
       "190  0.121952  2.657476  0.133050  \n",
       "191  0.129303  2.784312  0.168895  \n",
       "192  0.158453  2.679772  0.131728  \n",
       "193  0.207454  2.138608  0.123306  \n",
       "194  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 24 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DB_Voice_Features.csv')\n",
    "\n",
    "print('Shape: ',data.shape)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569ef38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = ['name']\n",
    "data = data.drop(non_numeric_columns, axis=1)\n",
    "\n",
    "X = data.drop('status', axis=1)\n",
    "y = data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92474b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9115e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy (Before Optimization): 0.9487179487179487\n",
      "KNN Classification Report (Before Optimization):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.94      1.00      0.97        32\n",
      "\n",
      "    accuracy                           0.95        39\n",
      "   macro avg       0.97      0.86      0.90        39\n",
      "weighted avg       0.95      0.95      0.95        39\n",
      "\n",
      "\n",
      "KNN Accuracy (After Optimization): 0.9743589743589743\n",
      "KNN Classification Report (After Optimization):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.97      1.00      0.98        32\n",
      "\n",
      "    accuracy                           0.97        39\n",
      "   macro avg       0.98      0.93      0.95        39\n",
      "weighted avg       0.98      0.97      0.97        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_classifier_before = KNeighborsClassifier()\n",
    "\n",
    "knn_classifier_before.fit(X_train, y_train)\n",
    "\n",
    "knn_predictions_before = knn_classifier_before.predict(X_test)\n",
    "\n",
    "accuracy_before = accuracy_score(y_test, knn_predictions_before)\n",
    "\n",
    "print(\"KNN Accuracy (Before Optimization):\", accuracy_before)\n",
    "print(\"KNN Classification Report (Before Optimization):\\n\", classification_report(y_test, knn_predictions_before))\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_knn_classifier = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'], metric=best_params['metric'])\n",
    "\n",
    "best_knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "knn_predictions_after = best_knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy_after = accuracy_score(y_test, knn_predictions_after)\n",
    "\n",
    "print(\"\\nKNN Accuracy (After Optimization):\", accuracy_after)\n",
    "print(\"KNN Classification Report (After Optimization):\\n\", classification_report(y_test, knn_predictions_after))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2901212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (Before Optimization): 0.8974358974358975\n",
      "Logistic Regression Classification Report (Before Optimization):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60         7\n",
      "           1       0.89      1.00      0.94        32\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.94      0.71      0.77        39\n",
      "weighted avg       0.91      0.90      0.88        39\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy (After Optimization): 0.8974358974358975\n",
      "Logistic Regression Classification Report (After Optimization):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60         7\n",
      "           1       0.89      1.00      0.94        32\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.94      0.71      0.77        39\n",
      "weighted avg       0.91      0.90      0.88        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier_before = LogisticRegression()\n",
    "\n",
    "logistic_classifier_before.fit(X_train, y_train)\n",
    "\n",
    "logistic_predictions_before = logistic_classifier_before.predict(X_test)\n",
    "\n",
    "accuracy_before = accuracy_score(y_test, logistic_predictions_before)\n",
    "\n",
    "print(\"Logistic Regression Accuracy (Before Optimization):\", accuracy_before)\n",
    "print(\"Logistic Regression Classification Report (Before Optimization):\\n\", classification_report(y_test, logistic_predictions_before))\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_logistic_classifier = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'])\n",
    "\n",
    "best_logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "logistic_predictions_after = best_logistic_classifier.predict(X_test)\n",
    "\n",
    "accuracy_after = accuracy_score(y_test, logistic_predictions_after)\n",
    "\n",
    "print(\"\\nLogistic Regression Accuracy (After Optimization):\", accuracy_after)\n",
    "print(\"Logistic Regression Classification Report (After Optimization):\\n\", classification_report(y_test, logistic_predictions_after))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb748049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Metrics:\n",
      "Accuracy: 0.9743589743589743\n",
      "Precision: 0.9696969696969697\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9846153846153847\n",
      "Confusion Matrix:\n",
      " [[ 6  1]\n",
      " [ 0 32]]\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8974358974358975\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9411764705882353\n",
      "Confusion Matrix:\n",
      " [[ 3  4]\n",
      " [ 0 32]]\n"
     ]
    }
   ],
   "source": [
    "knn_predictions = best_knn_classifier.predict(X_test)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_precision = precision_score(y_test, knn_predictions)\n",
    "knn_recall = recall_score(y_test, knn_predictions)\n",
    "knn_f1 = f1_score(y_test, knn_predictions)\n",
    "knn_confusion = confusion_matrix(y_test, knn_predictions)\n",
    "\n",
    "logistic_predictions = best_logistic_classifier.predict(X_test)\n",
    "\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_precision = precision_score(y_test, logistic_predictions)\n",
    "logistic_recall = recall_score(y_test, logistic_predictions)\n",
    "logistic_f1 = f1_score(y_test, logistic_predictions)\n",
    "logistic_confusion = confusion_matrix(y_test, logistic_predictions)\n",
    "\n",
    "print(\"KNN Metrics:\")\n",
    "print(\"Accuracy:\", knn_accuracy)\n",
    "print(\"Precision:\", knn_precision)\n",
    "print(\"Recall:\", knn_recall)\n",
    "print(\"F1-Score:\", knn_f1)\n",
    "print(\"Confusion Matrix:\\n\", knn_confusion)\n",
    "\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", logistic_accuracy)\n",
    "print(\"Precision:\", logistic_precision)\n",
    "print(\"Recall:\", logistic_recall)\n",
    "print(\"F1-Score:\", logistic_f1)\n",
    "print(\"Confusion Matrix:\\n\", logistic_confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6d2a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both KNN and Logistic Regression have the same precision for class Healthy.\n",
      "KNN has a higher recall for class Healthy.\n",
      "KNN has a higher f1-score for class Healthy.\n",
      "\n",
      "KNN has a higher precision for class PD.\n",
      "Both KNN and Logistic Regression have the same recall for class PD.\n",
      "KNN has a higher f1-score for class PD.\n"
     ]
    }
   ],
   "source": [
    "knn_classification_report = classification_report(y_test, knn_predictions, target_names=['Healthy', 'PD'], output_dict=True)\n",
    "\n",
    "# Calculate classification report for Logistic Regression\n",
    "logistic_classification_report = classification_report(y_test, logistic_predictions, target_names=['Healthy', 'PD'], output_dict=True)\n",
    "\n",
    "# Function to compare metrics\n",
    "def compare_metrics(metric, label):\n",
    "    knn_metric = knn_classification_report[label][metric]\n",
    "    logistic_metric = logistic_classification_report[label][metric]\n",
    "    \n",
    "    if knn_metric > logistic_metric:\n",
    "        print(f\"KNN has a higher {metric} for class {label}.\")\n",
    "    elif knn_metric < logistic_metric:\n",
    "        print(f\"Logistic Regression has a higher {metric} for class {label}.\")\n",
    "    else:\n",
    "        print(f\"Both KNN and Logistic Regression have the same {metric} for class {label}.\")\n",
    "\n",
    "# Compare metrics for class label 'Healthy'\n",
    "compare_metrics(\"precision\", 'Healthy')\n",
    "compare_metrics(\"recall\", 'Healthy')\n",
    "compare_metrics(\"f1-score\", 'Healthy')\n",
    "\n",
    "print()\n",
    "\n",
    "# Compare metrics for class label 'PD'\n",
    "compare_metrics(\"precision\", 'PD')\n",
    "compare_metrics(\"recall\", 'PD')\n",
    "compare_metrics(\"f1-score\", 'PD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df2829",
   "metadata": {},
   "source": [
    "#  Discuss the results obtained (different metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59496095",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b60ef7",
   "metadata": {},
   "source": [
    "# Both models have high accuracy, with KNN achieving approximately 97% and Logistic Regression achieving approximately 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3535502",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56feb869",
   "metadata": {},
   "source": [
    "# KNN has a precision of approximately 97%, while Logistic Regression has a precision of approximately 89%. Precision measures the proportion of true positive predictions among all positive predictions. KNN has slightly better precision, indicating that it makes fewer false-positive predictions compared to Logistic Regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12427a21",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a778a",
   "metadata": {},
   "source": [
    "#  Both models have perfect recall (100%). Recall measures the proportion of true positive predictions among all actual positives. In this context, high recall means that both models correctly identify all individuals with PD. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f5db3",
   "metadata": {},
   "source": [
    "# F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c593dff",
   "metadata": {},
   "source": [
    "# KNN has an F1-score of approximately 98%, while Logistic Regression has an F1-score of approximately 94%. The F1-score is the harmonic mean of precision and recall and provides a balanced measure of a model's performance. KNN has a higher F1-score, indicating a better overall balance between precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c55217",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a44bc",
   "metadata": {},
   "source": [
    "# The confusion matrix provides a more detailed view of the model's performance. For KNN, there are 6 true negatives, which correctly identified healthy individuals. 1 false positive shows a healthy individual misclassified as having PD. 32 true positives which correctly identified individuals with PD. For Logistic Regression, there are 3 true negatives, 4 false positives, and 32 true positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd0f1d",
   "metadata": {},
   "source": [
    "\n",
    "# KNN shows to have a slightly better precision and shows it may be more reliable in not misclassifying healthy individuals as having PD. Logistic Regression has a lower FPR which is importaint in clinical practices to avoid wrong and unnecessary concerns for healthy individuals. \n",
    "\n",
    "# For clinical Implications, KNN methods has a higher precision, and Logistic Regression have higher recall.Logistic Regression in terms of precision, F1-score will have better performance, while KNN is better at identifying PD with more accurate positive true and false rates than negatives.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
